#include <ros/ros.h>
#include <stdlib.h>
#include <math.h>
#include <sensor_msgs/PointCloud2.h> 
#include <pcl_ros/point_cloud.h> //to convert between PCL and ROS
#include <pcl/conversions.h>
#include <pcl/point_types.h>
#include <pcl/point_cloud.h>
//#include <pcl/PCLPointCloud2.h> //PCL is migrating to PointCloud2 
#include <pcl/common/common_headers.h>
#include <pcl-1.7/pcl/point_cloud.h>
#include <pcl-1.7/pcl/PCLHeader.h>

// basic file operations
#include <fstream>

using namespace std;

int counter;
bool published;

ros::Publisher cropped_cloud_pub;

//save as RAW
void saveImage(int heightmap[]) {
	//	unsigned char val[320][240];
	FILE *image = fopen("heightmap.data", "wb");
	for (unsigned int xIndex = 0; xIndex < 20; xIndex++)
	{
		for (unsigned int yIndex = 0; yIndex < 20; yIndex++)
		{
			int index = xIndex + yIndex * 20;
			fwrite(&heightmap[index], sizeof(unsigned char), 1, image);
		}
	}
	fclose(image); 
	ROS_INFO("done writing image");

}




void take_snapshot(const sensor_msgs::PointCloud2& input) {

	ROS_INFO("Taking snapshot");

	pcl::PointCloud<pcl::PointXYZ> cloud;
	pcl::fromROSMsg(input,cloud);
	ROS_INFO("width: %d", cloud.width);
	ROS_INFO("height: %d", cloud.height);

	int cloudsize = (cloud.width) * (cloud.height);

	//for debug purposes
	double maxX = -100;
	double maxY = -100;
	double maxZ = -100;
	double minX = 100;
	double minY = 100;
	double minZ = 100;

	//we're interesting only in the 1m x 1m square in front of the robot
	double xMin = -0.5;
	double xMax = 0.5;
	double yMin = 0.5;
	double yMax = 1.5;

	//and we need to limit the height range
	//height range should be be centered on ground instead of the height of the wobbler,
	//wobbler is about 1 meter of the ground (but wobbler height is considered height 0)
	double zMin = -3;
	double zMax = 1;

	//the square will have a resolution of 5cm, so its 20x20 pixels (400 total pixels)
	int xdim = 20;
	int ydim = 20;
	double intensities[xdim*ydim];

	//initialize with nan
	for (int i=0; i < sizeof(intensities)/8; i++) {
		intensities[i] = NAN;
	}

	for (int i=0; i< cloudsize; i++) {

		//TODO tf to gravity frame

		//in the gazebo's frame the point cloud's y is in the -z direction,
		//z is in the y direction, and x is the same
		double x = cloud[i].x;
		double y = cloud[i].z;
		double z = -cloud[i].y;


		//only care about points that fall in our square
		if (xMin < x && xMax > x &&
				yMin < y && yMax > y) {

			//for debug purposes
			if (x < minX) {
				minX = x;
			}
			if (y < minY) {
				minY = y;
			}
			if (z < minZ) {
				minZ = z;
			}
			if (x > maxX) {
				maxX = x;
			}
			if (y > maxY) {
				maxY = y;
			}
			if (z > maxZ) {
				maxZ = z;
			}

			double fraction = (x - xMin)/(xMax - xMin);
			//round by adding 0.5 and casting (truncating)
			int xIndex = (int)((xdim-1) * fraction + 0.5);

			fraction = (y - yMin)/(yMax - yMin);
			int yIndex = (int)((ydim-1) * fraction + 0.5);

			int index = xIndex + yIndex * xdim;

			fraction = (z - zMin)/(zMax - zMin);

			//scale fall in range 0-199
			//255 is reserved for unknown pixels, the gap 200-254 may help the 
			//future neural net more easily differentiate unknowns from other values
			double value = fraction * 199;

			//save the pixel as the highest point we come across
			if (isnan(intensities[index]) || intensities[index] < value) {
				intensities[index] = value;
			}
		}
		else {
			//otherwise we don't want these points, set them to NAN
			cloud[i].x = NAN;
			cloud[i].z = NAN;
			cloud[i].y = NAN;
		}
	}

	int heightmap[xdim*ydim];
	//intensities array of doubles to ints for the heightmap
	for (int i=0; i < sizeof(intensities)/8; i++) {

		if(isnan(intensities[i])) {
			//anything still nan is unknown value so set it to 255
			heightmap[i] = 255;
		}
		else {
			heightmap[i] = (int)(intensities[i] + 0.5);
		}
	}

	ofstream heightfile("values.txt", ios::out | ios::binary);
	for (int i=0; i < sizeof(intensities)/8; i++) {

		if(i%20 == 0) {
			heightfile << "\n";
		}
		heightfile << heightmap[i] << ", ";
	}
	heightfile.close();

	ofstream bounds("bounds.txt", ios::out | ios::binary);
	bounds << minX << "\n";
	bounds << maxX << "\n";
	bounds << minY << "\n";
	bounds << maxY << "\n";
	bounds << minZ << "\n";
	bounds << maxZ << "\n";
	bounds.close();

	//write image file
	saveImage(heightmap);

	sensor_msgs::PointCloud2 croppedCloud;
	pcl::toROSMsg(cloud, croppedCloud);

	if(!cropped_cloud_pub) {
		ROS_WARN("Publisher invalid!");
	}
	else {
		cropped_cloud_pub.publish(croppedCloud);
		ROS_INFO("Publisher VALID!!!!");
	}

	//TODO
	//now crop the cloud to the spot in front of the robot (might have to do a base_link to kinect transform)

	//calculate where the pixels boundaries will be, and with any cropping really, doesn't even have to be in front
	//of the robot for now, take an average of the z values of all points falling in a pixel's boundary, scale 0-200,
	// and leave 255 reserved for unknown.
	//scan through all pixels, if nan, look at neighbors. If num_neighbors >=4 fill it in with average of its neighbors
	//else leave it as nan
	//Scan through pixels again filling in for a second pass. Repeat until a scan fails to fill in any pixels.
	//fill any remaining nan pixels with 255
	//output pixel as an image, see what it is looks like

	//maybe do compression aith an autocorrelator, backprop vs the otherone
	//compress down to n_terms and back up to full image

	//load this pic as heightmap in blender. compare shape original scan 



}


void pointCloudCallback(const sensor_msgs::PointCloud2& cloud) {
	if (!published) {
		take_snapshot(cloud);
		published = true;
	}
}

int main(int argc, char** argv){

	ros::init(argc, argv, "data_collection");

	counter = 0;
	published = false;

	ROS_INFO("running data collection loop!");

	//TODO spawn in random spot
	//check accerometer, speed, collisions to see if in a valid pose (aka upright, not colliding)
	//save point cloud
	//attempt to drive a meter or something, while checking for tipping, failure to progress, collision, etc 
	//determine whether successful, saved pt cloud success label together as a pair

	ros::NodeHandle n;

	cropped_cloud_pub = n.advertise<sensor_msgs::PointCloud2>("/cropped_cloud", 1);

	ros::Subscriber pcl_subscriber = n.subscribe("/kinect/depth/points", 1, pointCloudCallback);

	ros::spin();
	return 0;
}
